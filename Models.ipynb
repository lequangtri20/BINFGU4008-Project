{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNEcLkf/h7BPpnigmOpGJOk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"bARlBq_MF4VT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sfpdMy-AhMM2"},"outputs":[],"source":["class BaseModel(nn.Module):\n","\n","  def __init__(self, device):\n","\n","    super(BaseModel, self).__init__()\n","    self.device = device\n","\n","  def forward(self, X):\n","\n","    return None\n","\n","  def train_model(self, criterion, optimizer, dataloader):\n","\n","    self.train()\n","\n","    all_labels = torch.empty(0).to(self.device)\n","    all_preds = torch.empty(0).to(self.device)\n","\n","    running_loss = 0.0\n","\n","    for i, instance in enumerate(dataloader):\n","\n","      image_input, tab_input, labels = instance[0].to(torch.float32).to(self.device), instance[1].to(torch.float32).to(self.device).reshape(-1, 1), instance[2].to(torch.float32).to(self.device)\n","\n","      optimizer.zero_grad()\n","\n","      outputs = self(image_input, tab_input).to(torch.float32)\n","\n","      loss = criterion(outputs.view(-1, 1), labels.view(-1, 1))\n","      loss.backward()\n","\n","      optimizer.step()\n","\n","      running_loss += loss.item()\n","\n","      all_labels = torch.cat((all_labels, labels), dim = 0)\n","      all_preds = torch.cat((all_preds, outputs), dim = 0)\n","\n","      if (i + 1) % 10 == 0:\n","        print(f'Batch {i + 1} Loss = {loss}')\n","\n","    return all_labels.detach().cpu().numpy(), all_preds.detach().cpu().numpy(), running_loss / len(dataloader)\n","\n","  def evaluate_model(self, criterion, dataloader):\n","\n","    self.eval()\n","\n","    all_labels = torch.empty(0).to(device)\n","    all_preds = torch.empty(0).to(device)\n","\n","    running_loss = 0.0\n","\n","    with torch.no_grad():\n","\n","      for i, instance in enumerate(dataloader):\n","\n","        image_input, tab_input, labels = instance[0].to(torch.float32).to(device), instance[1].to(torch.float32).to(device).reshape(-1, 1), instance[2].to(torch.float32).to(device)\n","\n","        outputs = self(image_input, tab_input).to(torch.float32).view(-1)\n","\n","        loss = criterion(outputs, labels.view(-1))\n","        running_loss += loss.item()\n","\n","        all_labels = torch.cat((all_labels, labels), dim = 0)\n","        all_preds = torch.cat((all_preds, outputs), dim = 0)\n","\n","    return all_labels.cpu().numpy(), all_preds.cpu().numpy(), running_loss / len(dataloader)"]}]}